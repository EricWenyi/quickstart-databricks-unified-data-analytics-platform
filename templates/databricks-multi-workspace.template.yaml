AWSTemplateFormatVersion: 2010-09-09
Description: >-
  This template creates all the resources needed to setup a Databricks workspace in an AWS account.
  
Metadata:
  AWS::CloudFormation::Interface:
    ParameterGroups:
      - Label:
          default: "Multiple Workspace Configuration Parameters"
        Parameters:
          - TagName
          - MWSaccountId
          - AWSAccountId 
          - AWSRegion
          - IAMRole
          - BucketName
          - DeploymentName
          - Username
          - Password
      - Label:
          default: "Customer Managed Key Parameters for encrypting workspace notebooks (Premium Tier)"
        Parameters:
          - KeyArn
          - KeyAlias  
          - KeyRegion
      - Label:
          default: "Customer Managed VPC Parameters (Premium Tier)"
        Parameters:
          - VPCID
          - SubnetIDs
          - SecurityGroupIDs
          - NoPublicIP
      - Label:
          default: "AWS QuickStart Configuration Parameters"
        Parameters:
          - QSS3BucketName
          - QSS3KeyPrefix
    ParameterLabels:
      MWSaccountId:
        default: The Databricks Multi-workspace Master Account ID
      AWSAccountId:
        default: The Customerâ€™s AWS Account ID required for building the IAM role
      AWSRegion:
        default: A valid and supported AWS region where the customer's Databricks workspace will be deployed
      IAMRole:
        default: The name of the IAM cross account role name to be created
      BucketName:
        default: The name of the S3 root bucket for the workspace
      DeploymentName:
        default: The name of your workspace  
      Username:
        default: Username for REST API call authentication
      Password:
        default: The password corresponding the Username 
      KeyArn:
        default: The KMS customer managed Key ARN.   
      KeyAlias:
        default: The KMS customer managed alias name.
      KeyRegion:
        default: The AWS region where the KMS Key was created.   
      VPCID:
        default: The customer managed VPC Id - format is vpc-xxxxxxxxxxxxxxxx
      SubnetIDs:
        default: The Subnet IDs - format is subnet-xxxxxxxxxxxxxxxxx
      SecurityGroupIDs:
        default: The Security group IDs - format is sg-xxxxxxxxxxxxxxxxx
      NoPublicIP:
        default: Disable Public IP
      QSS3BucketName:
        default: QSS3BucketName
      QSS3KeyPrefix:
        default: QSS3KeyPrefix   
      TagName:
        default: Tag name

Outputs:
  CustomerManagedVPCIAMRoleARN:
    Description: The customer managed cross account role ARN
    Condition: CustomerManagedVPC
    Value: !GetAtt 
      - accessRoleCustomerManagedVPC
      - Arn
  DBManagedVPCIAMRoleARN:
    Description: The ARN of the cross account role
    Condition: CreateDBManagedVPC
    Value: !GetAtt 
      - accessRoleDBManagedVPC
      - Arn
  S3BucketName:
    Description: The name of the S3 root bucket
    Value: !Ref assetsS3Bucket
  CustomerManagedKeyId:
    Description: Id of the created customer managed key object  
    Value: !GetAtt createCustomerManagedKey.CustomerManagedKeyId
    Condition: IsKMSKeyProvided
  CredentialsId:
    Description: Credential Id
    Value: !GetAtt createCredentials.CredentialsId
  ExternalId:
    Description: Databriks External Id
    Value: !GetAtt createCredentials.ExternalId
  StorageConfigId:
    Description: Storage configuration Id
    Value: !GetAtt createStorageConfiguration.StorageConfigId
  WorkspaceStatus:
    Description: Status of the requested workspace
    Value: !GetAtt createWorkspace.WorkspaceStatus

Parameters:
  MWSaccountId:
    Description: The Databricks Account Id in the following format aaaaaaaa-bbbb-cccc-dddd-eeeeeeeeeeee.
    MinLength: '32'
    Type: String
    Default: aaaaaaaa-bbbb-cccc-dddd-eeeeeeeeeeee 
  AWSAccountId:
    Description: The Customer's Account Id in the following format 111111111111.
    MinLength: '12'
    Type: String
    Default: 111111111111
  AWSRegion:
    Description: A valid AWS Region where the workspace will be created.
    MinLength: '9'
    AllowedValues:
       - us-east-1
       - us-west-1
       - us-west-2
    Type: String
    Default: us-west-2
  IAMRole:
    Description: The name of the cross account role. Only Alphnumeric characters with a minimum length of 8.
    AllowedPattern: '^[0-9a-zA-Z]+([0-9a-zA-Z-]*[0-9a-zA-Z])*$'
    MinLength: '8'
    Type: String
  BucketName:
    Description: The name of the S3 root bucket. Only Alphnumeric characters with a minimum length of 8.
    AllowedPattern: '^[0-9a-zA-Z]+([0-9a-zA-Z-]*[0-9a-zA-Z])*$'
    MinLength: '8'
    Type: String
  DeploymentName:
    Description: Your workspace url will consists of <DeploymentName>.cloud.databricks.com. Only Alphnumeric characters with a minimum length of 8.
    AllowedPattern: '^[0-9a-zA-Z]+([0-9a-zA-Z-]*[0-9a-zA-Z])*$'
    MinLength: '8'
    Type: String  
  Username:
    Description: Username for REST API call authentication.
    MinLength: '1'
    Type: String
  Password:
    Description: Password for REST API call authentication. Minimum length of 8 characters.
    MinLength: '8'
    NoEcho: 'true'
    Type: String
  KeyArn:
    Description: The KMS Key ARN used by Databricks to encrypt/decrypt the notebooks for a workspace.
    Default: ''
    Type: String
  KeyAlias:
    Description: Leave blank if the Key ARN is NOT specified.
    Default: ''
    Type: String 
  KeyRegion:
    Description: Leave blank if the Key ARN is NOT specified. 
    Default: ''
    Type: String
  VPCID:
    Description: Existing Virtual Private Cloud (VPC) Id where to create the new workspace. If not supplied, the new workspace will be created in a VPC created by Databricks.
    Type: String  
    Default: ''  
  SecurityGroupIDs:
    Description: The name of the of Security Group in your Virtual Private Cloud (VPC)
    Type: String
    Default: ''
  SubnetIDs:
    Description: The list of SubnetIds in your Virtual Private Cloud (VPC) seperated by a comma(,). Minimum of 2 SuubnetIDs is required.
    Type: String 
    Default: ''
  NoPublicIP:
    Description: Disable Public IP for cluster worker nodes.
    Type: String
    AllowedValues:
      - 'true'
      - 'false'
    Default: 'false'  
  QSS3BucketName:
    Description: The S3 bucket where the Templates and Functions exists in the git repository
    AllowedPattern: '^[0-9a-zA-Z]+([0-9a-zA-Z-]*[0-9a-zA-Z])*$'
    Default: aws-quickstart
    Type: String
  QSS3KeyPrefix:
    Description: The S3 bucket folder Prefix where the AWS QuickStart Templates and Functions exist
    AllowedPattern: '^[0-9a-zA-Z-/]*$'
    Default: quickstart-databricks-unified-data-analytics-platform/
    Type: String
  TagName:
    Description: A TagName to be used for all AWS objects created
    MinLength: '8'
    Type: String
  

Conditions:
  # Condition to check if a VPC Id is provided by the user
  CustomerManagedVPC: !Not [!Equals [!Ref VPCID, '']]
   # Condition to check if a VPC Id is not provided by the user
  CreateDBManagedVPC: !Equals [!Ref VPCID, '']
  # Condition to check if a KMS Key ID is provided by the user
  IsKMSKeyProvided: !Not [!Equals [!Ref KeyArn, '']]
 

Rules:
  
# Ensure that the SubnetIds and SecurityGroupIds are provided, if the user provides a customer managed VPC Id  
  CustomerManagedVPC:
    RuleCondition: !Not [!Equals [!Ref VPCID, '']]
    Assertions:
    - Assert: !Not [!Equals ['', !Ref SubnetIDs]]
      AssertDescription: SubnetIDs is required when VPCID is provided
    - Assert: !Not [!Equals ['', !Ref SecurityGroupIDs]]
      AssertDescription: SecurityGroupIDs is required when VPCID is provided
      
# Ensure that the KeyAlias and KeyRegion are provided, if user provides a customer managed KMS   
  CustomerManagedKMS:
    RuleCondition: !Not [!Equals [!Ref KeyArn, '']]
    Assertions:    
    - Assert: !Not [!Equals ['', !Ref KeyAlias ]]
      AssertDescription: KeyAlias is required when the KeyArn is provided
    - Assert: !Not [!Equals ['', !Ref KeyRegion ]]
      AssertDescription: KeyRegion is required when the KeyArn is provided

# Assertion rule to prevent changing the QuickStart Bucket name and Prefix parameter
# This rule must be UNCOMMNETED if it is entended to clone the git repo to make modifications prior to promote the changes

#  AWSQuickStartGitParametersSettings:
#    Assertions:    
#    - Assert: !Equals ['aws-quickstart', !Ref QSS3BucketName]
#      AssertDescription: The QSS3BucketName MUST be set to aws-quickstart  
#    - Assert: !Equals ['quickstart-databricks-unified-data-analytics-platform/', !Ref QSS3KeyPrefix]
#      AssertDescription: The QSS3KeyPrefix MUST be set to - quickstart-databricks-unified-data-analytics-platform/
        
Resources:
  # Cross account access role for Databricks created and managed VPC
  accessRoleDBManagedVPC:
    Type: 'AWS::IAM::Role'
    Condition: CreateDBManagedVPC
    Properties:
      RoleName: !Ref IAMRole
      AssumeRolePolicyDocument:
        Statement:
          - Action: 'sts:AssumeRole'
            Condition:
              StringEquals: 
                'sts:ExternalId': !Sub '${MWSaccountId}'
            Effect: Allow
            Principal:
              AWS: !Join 
                - ''
                - - 'arn:aws:iam::'
                  - '414351767826'
                  - ':root'
            Sid: ''
        Version: 2012-10-17
      Path: /
      Policies:
        - PolicyDocument:
            Statement:
              - Sid: Stmt1403287045000
                Effect: Allow
                Action:
                  - 'ec2:AssociateDhcpOptions'
                  - 'ec2:AssociateIamInstanceProfile'
                  - 'ec2:AssociateRouteTable'
                  - 'ec2:AttachInternetGateway'
                  - 'ec2:AttachVolume'
                  - 'ec2:AuthorizeSecurityGroupEgress'
                  - 'ec2:AuthorizeSecurityGroupIngress'
                  - 'ec2:CancelSpotInstanceRequests'
                  - 'ec2:CreateDhcpOptions'
                  - 'ec2:CreateInternetGateway'
                  - 'ec2:CreateKeyPair'
                  - 'ec2:CreatePlacementGroup'
                  - 'ec2:CreateRoute'
                  - 'ec2:CreateSecurityGroup'
                  - 'ec2:CreateSubnet'
                  - 'ec2:CreateTags'
                  - 'ec2:CreateVolume'
                  - 'ec2:CreateVpc'
                  - 'ec2:CreateVpcPeeringConnection'
                  - 'ec2:DeleteInternetGateway'
                  - 'ec2:DeleteKeyPair'
                  - 'ec2:DeletePlacementGroup'
                  - 'ec2:DeleteRoute'
                  - 'ec2:DeleteRouteTable'
                  - 'ec2:DeleteSecurityGroup'
                  - 'ec2:DeleteSubnet'
                  - 'ec2:DeleteTags'
                  - 'ec2:DeleteVolume'
                  - 'ec2:DeleteVpc'
                  - 'ec2:DescribeAvailabilityZones'
                  - 'ec2:DescribeIamInstanceProfileAssociations'
                  - 'ec2:DescribeInstanceStatus'
                  - 'ec2:DescribeInstances'
                  - 'ec2:DescribePlacementGroups'
                  - 'ec2:DescribePrefixLists'
                  - 'ec2:DescribeReservedInstancesOfferings'
                  - 'ec2:DescribeRouteTables'
                  - 'ec2:DescribeSecurityGroups'
                  - 'ec2:DescribeSpotInstanceRequests'
                  - 'ec2:DescribeSpotPriceHistory'
                  - 'ec2:DescribeSubnets'
                  - 'ec2:DescribeVolumes'
                  - 'ec2:DescribeVpcs'
                  - 'ec2:DetachInternetGateway'
                  - 'ec2:DisassociateIamInstanceProfile'
                  - 'ec2:ModifyVpcAttribute'
                  - 'ec2:ReplaceIamInstanceProfileAssociation'
                  - 'ec2:RequestSpotInstances'
                  - 'ec2:RevokeSecurityGroupEgress'
                  - 'ec2:RevokeSecurityGroupIngress'
                  - 'ec2:RunInstances'
                  - 'ec2:TerminateInstances'
                Resource:
                  - '*'
              - Effect: Allow
                Action:
                  - 'iam:CreateServiceLinkedRole'
                  - 'iam:PutRolePolicy'
                Resource: >-
                  arn:aws:iam::*:role/aws-service-role/spot.amazonaws.com/AWSServiceRoleForEC2Spot
                Condition:
                  StringLike:
                    'iam:AWSServiceName': spot.amazonaws.com
            Version: 2012-10-17
          PolicyName: databricks-cross-account-iam-role-policy
      Tags:
        -
          Key: Name
          Value: !Join
                  - '_'
                  - - !Ref TagName
                    - !Sub '${AWS::StackName}-IAMRole'
  
  # Cross account access role for customer-managed VPC
  accessRoleCustomerManagedVPC:
    Type: 'AWS::IAM::Role'
    Condition: CustomerManagedVPC
    Properties:
      RoleName: !Ref IAMRole
      AssumeRolePolicyDocument:
        Statement:
          - Action: 'sts:AssumeRole'
            Condition:
               StringEquals: 
                'sts:ExternalId': !Sub '${MWSaccountId}'
            Effect: Allow
            Principal:
              AWS: !Join 
                - ''
                - - 'arn:aws:iam::'
                  - '414351767826'
                  - ':root'
            Sid: ''
        Version: 2012-10-17
      Path: /
      Policies:
        - PolicyDocument:
            Statement:
              - Sid: NonResourceBasedPermissions
                Effect: Allow
                Action:
                  - 'ec2:DescribeAvailabilityZones'
                  - 'ec2:DescribeInstanceStatus'
                  - 'ec2:DescribeInstances'
                  - 'ec2:DescribeInternetGateways'
                  - 'ec2:DescribeNatGateways'
                  - 'ec2:DescribeNetworkAcls'
                  - 'ec2:DescribePlacementGroups'
                  - 'ec2:DescribePrefixLists'
                  - 'ec2:DescribeReservedInstancesOfferings'
                  - 'ec2:DescribeRouteTables'
                  - 'ec2:DescribeSecurityGroups'
                  - 'ec2:DescribeSpotInstanceRequests'
                  - 'ec2:DescribeSpotPriceHistory'
                  - 'ec2:DescribeSubnets'
                  - 'ec2:DescribeVolumes'
                  - 'ec2:DescribeVpcAttribute'
                  - 'ec2:DescribeVpcs'
                  - 'ec2:CreatePlacementGroup'
                  - 'ec2:DeletePlacementGroup'
                  - 'ec2:CreateKeyPair'
                  - 'ec2:DeleteKeyPair'
                  - 'ec2:CreateTags'
                  - 'ec2:DeleteTags'
                  - 'ec2:RequestSpotInstances'
                  - 'ec2:CancelSpotInstanceRequests'
                Resource:
                  - '*'
              - Sid: InstancePoolsSupport
                Effect: Allow
                Action:
                  - 'ec2:AssociateIamInstanceProfile'
                  - 'ec2:DisassociateIamInstanceProfile'
                  - 'ec2:ReplaceIamInstanceProfileAssociation'
                Resource:
                  - !Sub arn:aws:ec2:${AWSRegion}:${AWSAccountId}:instance/* 
                Condition:
                  StringEquals:
                    'ec2:ResourceTag/Vendor': 'Databricks'
              - Sid: AllowEc2RunInstancePerTag
                Effect: Allow
                Action:
                  - 'ec2:RunInstances'
                Resource:
                  - !Sub arn:aws:ec2:${AWSRegion}:${AWSAccountId}:volume/*
                  - !Sub arn:aws:ec2:${AWSRegion}:${AWSAccountId}:instance/*
                Condition:
                  StringEquals:
                    'aws:RequestTag/Vendor': 'Databricks' 
              - Sid: AllowEc2RunInstanceImagePerTag
                Effect: Allow
                Action:
                  - 'ec2:RunInstances'
                Resource:
                  - !Sub arn:aws:ec2:${AWSRegion}:${AWSAccountId}:image/*
                Condition:
                  StringEquals:
                    'aws:ResourceTag/Vendor': 'Databricks'
              - Sid: AllowEc2RunInstancePerVPCid
                Effect: Allow
                Action:
                  - 'ec2:RunInstances'
                Resource:
                  - !Sub arn:aws:ec2:${AWSRegion}:${AWSAccountId}:network-interface/*
                  - !Sub arn:aws:ec2:${AWSRegion}:${AWSAccountId}:subnet/*
                  - !Sub arn:aws:ec2:${AWSRegion}:${AWSAccountId}:security-group/*
                Condition:
                  StringEquals:
                    'ec2:vpc' : !Sub 'arn:aws:ec2:${AWSRegion}:${AWSAccountId}:vpc/${VPCID}'
              - Sid: AllowEc2RunInstanceOtherResources
                Effect: Allow
                Action:
                  - 'ec2:RunInstances'
                NotResource:
                  - !Sub arn:aws:ec2:${AWSRegion}:${AWSAccountId}:image/* 
                  - !Sub arn:aws:ec2:${AWSRegion}:${AWSAccountId}:network-interface/*
                  - !Sub arn:aws:ec2:${AWSRegion}:${AWSAccountId}:subnet/*
                  - !Sub arn:aws:ec2:${AWSRegion}:${AWSAccountId}:security-group/*
                  - !Sub arn:aws:ec2:${AWSRegion}:${AWSAccountId}:volume/*
                  - !Sub arn:aws:ec2:${AWSRegion}:${AWSAccountId}:instance/*     
              - Sid: EC2TerminateInstancesTag
                Effect: Allow
                Action:
                  - 'ec2:TerminateInstances'
                Resource:
                  - !Sub arn:aws:ec2:${AWSRegion}:${AWSAccountId}:instance/*
                Condition:
                  StringEquals:
                    'ec2:ResourceTag/Vendor': 'Databricks'         
              - Sid: EC2AttachDetachVolumeTag
                Effect: Allow
                Action:
                  - 'ec2:AttachVolume'
                  - 'ec2:DetachVolume'
                Resource:
                  - !Sub arn:aws:ec2:${AWSRegion}:${AWSAccountId}:instance/* 
                  - !Sub arn:aws:ec2:${AWSRegion}:${AWSAccountId}:volume/*
                Condition:
                  StringEquals:
                    'ec2:ResourceTag/Vendor': 'Databricks'  
              - Sid: EC2CreateVolumeByTag
                Effect: Allow
                Action:
                  - 'ec2:CreateVolume'
                Resource:
                  - !Sub arn:aws:ec2:${AWSRegion}:${AWSAccountId}:volume/* 
                Condition:
                  StringEquals:
                    'aws:RequestTag/Vendor': 'Databricks'   
              - Sid: EC2DeleteVolumeByTag
                Effect: Allow
                Action:
                  - 'ec2:DeleteVolume'
                Resource:
                  - !Sub arn:aws:ec2:${AWSRegion}:${AWSAccountId}:volume/* 
                Condition:
                  StringEquals:
                    'ec2:ResourceTag/Vendor': 'Databricks'  
              - Effect: Allow
                Action:
                  - 'iam:CreateServiceLinkedRole'
                  - 'iam:PutRolePolicy'
                Resource: 
                  - arn:aws:iam::*:role/aws-service-role/spot.amazonaws.com/AWSServiceRoleForEC2Spot
                Condition:
                  StringLike:
                    'iam:AWSServiceName': spot.amazonaws.com 
              - Sid: VpcNonresourceSpecificActions
                Effect: Allow
                Action:
                  - 'ec2:AuthorizeSecurityGroupEgress'
                  - 'ec2:AuthorizeSecurityGroupIngress'
                  - 'ec2:RevokeSecurityGroupEgress'
                  - 'ec2:RevokeSecurityGroupIngress'
                Resource:
                  - !Sub arn:aws:ec2:${AWSRegion}:${AWSAccountId}:security-group/${SecurityGroupIDs}
                Condition:
                  StringEquals:
                    'ec2:vpc' : !Sub 'arn:aws:ec2:${AWSRegion}:${AWSAccountId}:vpc/${VPCID}'                                              
            Version: 2012-10-17
          PolicyName: databricks-cross-account-iam-role-policy
      Tags:
        -
          Key: Name
          Value: !Join
                  - '_'
                  - - !Ref TagName
                    - !Sub '${AWS::StackName}-IAMRole'

  # S3 root bucket requirements
  assetsS3Bucket:
    Type: AWS::S3::Bucket
    Properties:
      BucketName: !Ref BucketName
  bucketPolicy:
    Type: 'AWS::S3::BucketPolicy'
    Properties:
      PolicyDocument:
        Id: MyPolicy
        Version: 2012-10-17
        Statement:
          - Sid: Grant Databricks Access
            Effect: Allow
            Principal:
              AWS: arn:aws:iam::414351767826:root
            Action:
              - 's3:GetObject'
              - 's3:GetObjectVersion'
              - 's3:PutObject'
              - 's3:DeleteObject'
              - 's3:ListBucket'
              - 's3:GetBucketLocation'
            Resource:
              - !Sub 'arn:aws:s3:::${assetsS3Bucket}/*'
              - !Sub 'arn:aws:s3:::${assetsS3Bucket}'
      Bucket: !Ref assetsS3Bucket                  

  # Databricks API for configuring notebook encryption with a customer-managed KMS, if provided
  createCustomerManagedKey:
    Condition: IsKMSKeyProvided
    Type: Custom::CreateCustomerManagedKey
    Properties:
      ServiceToken: !GetAtt 'databricksApiFunction.Arn'
      action: 'CREATE_CUSTOMER_MANAGED_KEY'
      accountId: !Ref MWSaccountId
      key_arn: !Ref KeyArn
      key_alias: !Ref KeyAlias
      key_region: !Ref KeyRegion
      username: !Ref 'Username'
      password: !Ref 'Password'

  # Databricks API for workspace credentials
  createCredentials:
    Type: Custom::CreateCredentials
    Properties:
      ServiceToken: !GetAtt 'databricksApiFunction.Arn'
      action: 'CREATE_CREDENTIALS'
      accountId: !Ref MWSaccountId
      credentials_name: !Join
        - '-'
        - - !Ref DeploymentName
          - 'credentials'
      role_arn: !If [CustomerManagedVPC, !GetAtt 'accessRoleCustomerManagedVPC.Arn', !GetAtt 'accessRoleDBManagedVPC.Arn']
      username: !Ref 'Username'
      password: !Ref 'Password'

  # Databricks API for workspace storage configuration    
  createStorageConfiguration:
    Type: Custom::CreateStorageConfigurations
    Properties:
      ServiceToken: !GetAtt 'databricksApiFunction.Arn'
      action: 'CREATE_STORAGE_CONFIGURATIONS'
      accountId: !Ref MWSaccountId
      storage_config_name: !Join
        - '-'
        - - !Ref 'DeploymentName'
          - 'storage'
      s3bucket_name: !Ref assetsS3Bucket
      username: !Ref 'Username'
      password: !Ref 'Password'

  # Databricks API for customer managed VPC    
  createNetworks:
    DependsOn: createStorageConfiguration
    Condition: CustomerManagedVPC
    Type: Custom::createNetworks
    Properties:
      ServiceToken: !GetAtt 'databricksApiFunction.Arn'
      action: 'CREATE_NETWORKS'
      accountId: !Ref MWSaccountId
      network_name: !Join
        - '-'
        - - !Ref 'DeploymentName'
          - 'network'
      vpc_id: !Ref VPCID
      subnet_ids: !Ref SubnetIDs
      security_group_ids: !Ref SecurityGroupIDs
      username: !Ref 'Username'
      password: !Ref 'Password'

  # Databricks API for workspace creation    
  createWorkspace:
    Type: Custom::CreateWorkspace
    Properties:
      ServiceToken: !GetAtt 'databricksApiFunction.Arn'
      action: 'CREATE_WORKSPACES'
      accountId: !Ref MWSaccountId
      workspace_name: !Join
        - '-'
        - - !Ref 'DeploymentName'
          - 'workspace'
      deployment_name: !Ref 'DeploymentName'
      aws_region: !Ref AWSRegion
      credentials_id: !GetAtt createCredentials.CredentialsId
      storage_config_id: !GetAtt createStorageConfiguration.StorageConfigId
      username: !Ref 'Username'
      password: !Ref 'Password'
      network_id: !If [CustomerManagedVPC, !GetAtt 'createNetworks.NetworkId', '']
      no_public_ip: !Ref NoPublicIP   
  
  databricksApiFunction:
    DependsOn: CopyZips
    Type: AWS::Lambda::Function
    Properties:
      Description: Get workspace status
      Handler: rest_client.handler
      Runtime: python3.8
      Role: !GetAtt 'functionRole.Arn'
      Timeout: 120
      Code:
        S3Bucket: !Ref 'LambdaZipsBucket'
        S3Key: !Sub '${QSS3KeyPrefix}functions/packages/lambda.zip'   

  # IAM Role for lambda function execution
  functionRole:
    Type: AWS::IAM::Role
    Properties:
      AssumeRolePolicyDocument:
        Version: '2012-10-17'
        Statement:
          - Effect: Allow
            Principal:
              Service: lambda.amazonaws.com
            Action: sts:AssumeRole
      ManagedPolicyArns:
        - arn:aws:iam::aws:policy/service-role/AWSLambdaBasicExecutionRole
  #      - arn:aws:iam::aws:policy/IAMFullAccess
  #    Policies:
  #      - PolicyName: kmsUpdateRole
  #        PolicyDocument:
  #          Version: 2012-10-17
  #          Statement:
  #            - Effect: Allow
  #              Action: 'kms:*'
  #              Resource: '*'         

  # Resources to stage lambda.zip file
  LambdaZipsBucket:
    Type: AWS::S3::Bucket
  CopyZips:
    Type: Custom::CopyZips
    Properties:
      ServiceToken: !GetAtt 'CopyZipsFunction.Arn'
      DestBucket: !Ref 'LambdaZipsBucket'
      SourceBucket: !Ref 'QSS3BucketName'
      Prefix: !Ref 'QSS3KeyPrefix'
      Objects:
        - functions/packages/lambda.zip
  CopyZipsRole:
    Type: AWS::IAM::Role
    Properties:
      AssumeRolePolicyDocument:
        Version: '2012-10-17'
        Statement:
          - Effect: Allow
            Principal:
              Service: lambda.amazonaws.com
            Action: sts:AssumeRole
      ManagedPolicyArns:
        - arn:aws:iam::aws:policy/service-role/AWSLambdaBasicExecutionRole
      Path: /
      Policies:
        - PolicyName: lambda-copier
          PolicyDocument:
            Version: '2012-10-17'
            Statement:
              - Effect: Allow
                Action:
                  - s3:GetObject
                Resource:
                  - !Sub 'arn:aws:s3:::${QSS3BucketName}/${QSS3KeyPrefix}*'
              - Effect: Allow
                Action:
                  - s3:PutObject
                  - s3:DeleteObject
                Resource:
                  - !Sub 'arn:aws:s3:::${LambdaZipsBucket}/${QSS3KeyPrefix}*'

  CopyZipsFunction:
    Type: AWS::Lambda::Function
    Properties:
      Description: Copies objects from a source S3 bucket to a destination
      Handler: index.handler
      Runtime: python2.7
      Role: !GetAtt 'CopyZipsRole.Arn'
      Timeout: 240
      Code:
        ZipFile: |
          import json
          import logging
          import threading
          import boto3
          import cfnresponse
          def copy_objects(source_bucket, dest_bucket, prefix, objects):
              s3 = boto3.client('s3')
              for o in objects:
                  key = prefix + o
                  copy_source = {
                      'Bucket': source_bucket,
                      'Key': key
                  }
                  print('copy_source: %s' % copy_source)
                  print('dest_bucket = %s'%dest_bucket)
                  print('key = %s' %key)
                  s3.copy_object(CopySource=copy_source, Bucket=dest_bucket,
                        Key=key)
          def delete_objects(bucket, prefix, objects):
              s3 = boto3.client('s3')
              objects = {'Objects': [{'Key': prefix + o} for o in objects]}
              s3.delete_objects(Bucket=bucket, Delete=objects)
          def timeout(event, context):
              logging.error('Execution is about to time out, sending failure response to CloudFormation')
              cfnresponse.send(event, context, cfnresponse.FAILED, {}, None)
          def handler(event, context):
              # make sure we send a failure to CloudFormation if the function
              # is going to timeout
              timer = threading.Timer((context.get_remaining_time_in_millis()
                        / 1000.00) - 0.5, timeout, args=[event, context])
              timer.start()
              print('Received event: %s' % json.dumps(event))
              status = cfnresponse.SUCCESS
              try:
                  source_bucket = event['ResourceProperties']['SourceBucket']
                  dest_bucket = event['ResourceProperties']['DestBucket']
                  prefix = event['ResourceProperties']['Prefix']
                  objects = event['ResourceProperties']['Objects']
                  if event['RequestType'] == 'Delete':
                      delete_objects(dest_bucket, prefix, objects)
                  else:
                      copy_objects(source_bucket, dest_bucket, prefix, objects)
              except Exception as e:
                  logging.error('Exception: %s' % e, exc_info=True)
                  status = cfnresponse.FAILED
              finally:
                  timer.cancel()
                  cfnresponse.send(event, context, status, {}, None)
                  