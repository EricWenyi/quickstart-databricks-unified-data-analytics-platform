AWSTemplateFormatVersion: 2010-09-09
Description: >-
  This template creates resources for a Databricks workspace in your AWS account using the Multi-workspace API (Public Preview). The Multi-workspace API is required if you want to use the following optional features in preview: customer-managed VPCs and customer-managed keys for notebooks. Contact your Databricks representative to determine availability of these features for your subscription and deployment type. (qs-1r0odiedc)
  
Metadata:
  AWS::CloudFormation::Interface:
    ParameterGroups:
      - Label:
          default: "Required parameters"
        Parameters:
          - TagValue
          - MWSAccountId
          - AWSAccountId 
          - AWSRegion
          - DeploymentName
          - Username
          - Password
      - Label:
          default: "Required IAM role and S3 Bucket parameters"  
        Parameters:
          - IAMArnOrRoleQuestion
          - IAMArn
          - IAMRole
          - BucketName    
      - Label:
          default: "Optional: For customer-managed key for notebooks (Enterprise Tier)"
        Parameters:
          - KeyArn
          - KeyAlias  
          - KeyRegion
      - Label:
          default: "Optional: For customer-managed VPC (Premium Tier)"
        Parameters:
          - VPCID
          - SubnetIDs
          - SecurityGroupIDs
          - NoPublicIP
      - Label:
          default: "Only for testing template changes. Follow the deployment guide for more infomration."
        Parameters:
          - QSS3BucketName
          - QSS3KeyPrefix
    ParameterLabels:
      MWSAccountId:
        default: The Databricks multi-workspace master account ID
      AWSAccountId:
        default: Your AWS Account ID
      AWSRegion:
        default: AWS region for your new Databricks workspace.
      DeploymentName:
        default: Name for new workspace deployment (your workspace subdomain)
      Username:
        default: Your multi-workspace master account email address
      Password:
        default: Your multi-workspace master account password
      IAMArnOrRoleQuestion:
        default: Are you providing an existing IAM Role arn? 
      IAMArn:
        default: The already existing AWS IAM arn cross-account role to be used  
      IAMRole:
        default: Name for new AWS IAM cross-account role
      BucketName:
        default: Name for new root AWS S3 bucket  
      KeyArn:
        default: AWS KMS Key ARN for your customer-managed key in KMS
      KeyAlias:
        default: AWS KMS alias name for your customer-managed key in KMS
      KeyRegion:
        default: AWS region for your customer-managed key in KMS
      VPCID:
        default: ID for your VPC
      SubnetIDs:
        default: At least two AWS subnet IDs in your VPC. Format is subnet-xxxxxxxxxxxxxxxxx. These subnets cannot be shared with any other resources, including other Databricks workspaces or other non-Databricks resources.
      SecurityGroupIDs:
        default: The security group IDs
      NoPublicIP:
        default: Disable Public IP
      QSS3BucketName:
        default: QSS3BucketName
      QSS3KeyPrefix:
        default: QSS3KeyPrefix   
      TagValue:
        default: Tag value to use for all new AWS objects

Outputs:
  CustomerManagedVPCIAMRoleARN:
    Description: The customer managed cross account role ARN
    Condition: CustomerManagedVPC
    Value: !GetAtt 
      - accessRoleCustomerManagedVPC
      - Arn
  DBManagedVPCIAMRoleARN:
    Description: The ARN of the cross account role
    Condition: CreateDBManagedVPC
    Value: !GetAtt 
      - accessRoleDBManagedVPC
      - Arn
  S3BucketName:
    Description: The name of the S3 root bucket
    Value: !Ref assetsS3Bucket
  CustomerManagedKeyId:
    Description: ID of the created customer managed key object  
    Condition: IsKMSKeyProvided
    Value: !GetAtt createCustomerManagedKey.CustomerManagedKeyId
  CredentialsId:
    Description: Credential ID
    Value: !GetAtt createCredentials.CredentialsId
  ExternalId:
    Description: Databricks External ID
    Value: !GetAtt createCredentials.ExternalId
  NetworkId:
    Description: Databricks Network ID
    Condition: CustomerManagedVPC
    Value: !GetAtt createNetworks.NetworkId 
  StorageConfigId:
    Description: Storage configuration ID
    Value: !GetAtt createStorageConfiguration.StorageConfigId
  WorkspaceStatus:
    Description: Status of the requested workspace
    Value: !GetAtt createWorkspace.WorkspaceStatus
  WorkspaceStatusMessage:
    Description: Detailed status description of the requested workspace
    Value: !GetAtt createWorkspace.WorkspaceStatusMsg  

Parameters:
  MWSAccountId:
    Description: Your Databricks multi-workspace master account ID. Review your Multi-workspace API welcome email for this ID. Protect this ID like a credential. Format is aaaaaaaa-bbbb-cccc-dddd-eeeeeeeeeeee. 
    MinLength: '32'
    Type: String
    Default: aaaaaaaa-bbbb-cccc-dddd-eeeeeeeeeeee 
  AWSAccountId:
    Description: Your AWS Account ID. Format is a 12-digit number.
    MinLength: '12'
    Type: String
    Default: 111111111111
  AWSRegion:
    Description: AWS Region where the workspace will be created. Only some regions are supported. To use customer-managed keys to encrypt notebooks, you must specify either region us-east-1 or us-west-2.
    MinLength: '9'
    AllowedValues:
       - us-east-1
       - us-west-1
       - us-west-2
    Type: String
    Default: us-west-2
  DeploymentName:
    Description: 
      "This value defines your workspace's name and also the subdomain for your workspace URL. The workspace URL is <deployment-name>.cloud.databricks.com. Alphanumeric characters with a minimum length 8. To conform to subdomain rules, hyphens are also allowed but not as first or last character. The deployment name must be unique across all non-deleted workspaces across all AWS regions."
    AllowedPattern: '^[0-9a-zA-Z]+([0-9a-zA-Z-]*[0-9a-zA-Z])*$'
    MinLength: '8'
    Type: String  
  Username:
    Description: 
      "Your multi-workspace account email address, which is used for REST API authentication as your username. This is case sensitive. Use the same capitalization as when you sent it to your Databricks representative."
    AllowedPattern: '^[a-zA-Z0-9_.-]+@[a-zA-Z0-9-]+.[a-zA-Z0-9-.]+$'
    ConstraintDescription: "Must be a valid email format"
    MinLength: '8'
    Type: String
  Password:
    Description: Your multi-workspace account password, which is used for REST API authentication. This is case sensitive. Minimum length of 8 characters.
    MinLength: '8'
    NoEcho: 'true'
    Type: String
  IAMArnOrRoleQuestion:
    AllowedValues:
       - 'Yes'
       - 'No'
    Type: String
    Default: 'Yes'
  IAMArn: 
    Description: "Specify an existing IAM role arn if you have answered YES. For additional guidance in creating an IAM role, see https://docs.databricks.com/administration-guide/multiworkspace/iam-role.html"
    Type: String 
    Default: ''
  IAMRole:
    Description: The name for your new new cross-account role, if you answered NO. Only alphanumeric characters. Minimum length 8.
    Type: String
    Default: ''
  BucketName:
    Description: The name for your new S3 root bucket. Only alphanumeric characters. Minimum length 8.
    AllowedPattern: '^[0-9a-zA-Z]+([0-9a-zA-Z-]*[0-9a-zA-Z])*$'
    MinLength: '8'
    Type: String  
  KeyArn:
    Description: Set only if using the feature customer-managed key for notebooks. This field specifies the KMS Key ARN to use encrypt and decrypt the workspace notebooks in the control plane. To set up your KMS key, see https://docs.databricks.com/security/keys/customer-managed-keys-notebook-aws.html.
    Default: ''
    Type: String
  KeyAlias:
    Description: The KMS key alias. Leave empty if you didn't specify Key ARN.
    Default: ''
    Type: String 
  KeyRegion:
    Description: The AWS region of your KMS key. Leave empty if you didn't specify Key ARN.
    Default: ''
    Type: String
  VPCID:
    Description: Set only if using the customer-managed VPC feature. The ID for your AWS Virtual Private Cloud (VPC) in which to create the new workspace. Format is vpc-xxxxxxxxxxxxxxxx. For additional guidance, see https://docs.databricks.com/administration-guide/cloud-configurations/aws/customer-managed-vpc.html. If unspecified, Databricks creates the new workspace in a new VPC that Databricks creates. 
    Type: String  
    Default: ''  
  SecurityGroupIDs:
    Description: The name of one or more security groups in your Virtual Private Cloud (VPC). Format is sg-xxxxxxxxxxxxxxxxx. To provide multiple, separate with commas. Databricks must have access to at least one security group and no more than five security groups. You can reuse existing security groups rather than create new ones. For additional guidance, see https://docs.databricks.com/administration-guide/cloud-configurations/aws/customer-managed-vpc.html. Leave empty if you didn't specify VPCID.
    Type: String
    Default: ''
  SubnetIDs:
    Description: A list of at least two subnet IDs for subnets in your Virtual Private Cloud (VPC) separated by commas. These subnets CANNOT be shared with other workspaces nor any other non-Databricks resources. Each subnet must have a netmask between /17 and /25. Subnets must be private. Subnets must have outbound access to the public network using a NAT gateway and internet gateway, or other similar customer-managed appliance infrastructure. The NAT gateway must be set up in its own subnet that routes quad-zero (0.0.0.0/0) traffic to an internet gateway or other customer-managed appliance infrastructure. For additional guidance, see https://docs.databricks.com/administration-guide/cloud-configurations/aws/customer-managed-vpc.html. Leave empty if you didn't specify VPCID.
    Type: String 
    Default: ''
  NoPublicIP:
    Description: Disable Public IP for cluster worker nodes.
    Type: String
    AllowedValues:
      - ''
      - 'true'
      - 'false'
    Default: ''  
  QSS3BucketName:
    Description: Do not set unless testing/modifying this template. The name of the S3 bucket where the templates and functions exist in the git repository
    AllowedPattern: '^[0-9a-zA-Z]+([0-9a-zA-Z-]*[0-9a-zA-Z])*$'
    Default: aws-quickstart
    Type: String
  QSS3KeyPrefix:
    Description: Do not set unless testing/modifying this template. The S3 bucket folder prefix for the AWS QuickStart Templates and Functions.
    AllowedPattern: '^[0-9a-zA-Z-/]*$'
    Default: quickstart-databricks-unified-data-analytics-platform/
    Type: String
  TagValue:
    Description: 
      "All new AWS objects get a tag with key 'Name'. Specify the value for this tag so that you can identify all new AWS objects that this template creates."
    MinLength: '8'
    Type: String
    Default: databricks-quickstart-cloud-formation
  

Conditions:
  # Condition to check if a VPC ID is provided by the user
  CustomerManagedVPC: !Not [!Equals [!Ref VPCID, '']]
   # Condition to check if a VPC ID is not provided by the user
  CreateDBManagedVPC: !Equals [!Ref VPCID, '']
  # Condition to check if a KMS Key ID is provided by the user
  IsKMSKeyProvided: !Not [!Equals [!Ref KeyArn, '']]
 

Rules:
  
# Ensure that the SubnetIds and SecurityGroupIds are provided, if the user provides a customer managed VPC ID  
  CustomerManagedVPC:
    RuleCondition: !Not [!Equals [!Ref VPCID, '']]
    Assertions:
    - Assert: !Not [!Equals ['', !Ref SubnetIDs]]
      AssertDescription: SubnetIDs is required when VPCID is provided
    - Assert: !Not [!Equals ['', !Ref SecurityGroupIDs]]
      AssertDescription: SecurityGroupIDs is required when VPCID is provided
      
# Ensure that the KeyAlias and KeyRegion are provided, if user provides a customer managed KMS   
  CustomerManagedKMS:
    RuleCondition: !Not [!Equals [!Ref KeyArn, '']]
    Assertions:    
    - Assert: !Not [!Equals ['', !Ref KeyAlias ]]
      AssertDescription: KeyAlias is required when the KeyArn is provided
    - Assert: !Not [!Equals ['', !Ref KeyRegion ]]
      AssertDescription: KeyRegion is required when the KeyArn is provided

# Assertion rule to prevent changing the QuickStart Bucket name and Prefix parameter
# This rule must be UNCOMMENTED if it is intended to clone the git repo to make modifications prior to promote the changes

  AWSQuickStartGitParametersSettings:
    Assertions:    
    - Assert: !Equals ['aws-quickstart', !Ref QSS3BucketName]
      AssertDescription: The QSS3BucketName MUST be set to aws-quickstart  
    - Assert: !Equals ['quickstart-databricks-unified-data-analytics-platform/', !Ref QSS3KeyPrefix]
      AssertDescription: The QSS3KeyPrefix MUST be set to - quickstart-databricks-unified-data-analytics-platform/
        
Resources:
  # Cross account access role for Databricks created and managed VPC
  accessRoleDBManagedVPC:
    Type: 'AWS::IAM::Role'
    Condition: CreateDBManagedVPC
    Properties:
      RoleName: !Ref IAMRole
      AssumeRolePolicyDocument:
        Statement:
          - Action: 'sts:AssumeRole'
            Condition:
              StringEquals: 
                'sts:ExternalId': !Sub '${MWSAccountId}'
            Effect: Allow
            Principal:
              AWS: !Join 
                - ''
                - - 'arn:aws:iam::'
                  - '414351767826'
                  - ':root'
            Sid: ''
        Version: 2012-10-17
      Path: /
      Policies:
        - PolicyDocument:
            Statement:
              - Sid: Stmt1403287045000
                Effect: Allow
                Action:
                  - 'ec2:AssociateDhcpOptions'
                  - 'ec2:AssociateIamInstanceProfile'
                  - 'ec2:AssociateRouteTable'
                  - 'ec2:AttachInternetGateway'
                  - 'ec2:AttachVolume'
                  - 'ec2:AuthorizeSecurityGroupEgress'
                  - 'ec2:AuthorizeSecurityGroupIngress'
                  - 'ec2:CancelSpotInstanceRequests'
                  - 'ec2:CreateDhcpOptions'
                  - 'ec2:CreateInternetGateway'
                  - 'ec2:CreateKeyPair'
                  - 'ec2:CreatePlacementGroup'
                  - 'ec2:CreateRoute'
                  - 'ec2:CreateSecurityGroup'
                  - 'ec2:CreateSubnet'
                  - 'ec2:CreateTags'
                  - 'ec2:CreateVolume'
                  - 'ec2:CreateVpc'
                  - 'ec2:DeleteInternetGateway'
                  - 'ec2:DeleteKeyPair'
                  - 'ec2:DeletePlacementGroup'
                  - 'ec2:DeleteRoute'
                  - 'ec2:DeleteRouteTable'
                  - 'ec2:DeleteSecurityGroup'
                  - 'ec2:DeleteSubnet'
                  - 'ec2:DeleteTags'
                  - 'ec2:DeleteVolume'
                  - 'ec2:DeleteVpc'
                  - 'ec2:DescribeAvailabilityZones'
                  - 'ec2:DescribeIamInstanceProfileAssociations'
                  - 'ec2:DescribeInstanceStatus'
                  - 'ec2:DescribeInstances'
                  - 'ec2:DetachInternetGateway'
                  - 'ec2:DescribePlacementGroups'
                  - 'ec2:DescribePrefixLists'
                  - 'ec2:DescribeReservedInstancesOfferings'
                  - 'ec2:DescribeRouteTables'
                  - 'ec2:DescribeSecurityGroups'
                  - 'ec2:DescribeSpotInstanceRequests'
                  - 'ec2:DescribeSpotPriceHistory'
                  - 'ec2:DescribeSubnets'
                  - 'ec2:DescribeVolumes'
                  - 'ec2:DescribeVpcs'
                  - 'ec2:DetachInternetGateway'
                  - 'ec2:DisassociateIamInstanceProfile'
                  - 'ec2:ModifyVpcAttribute'
                  - 'ec2:ReplaceIamInstanceProfileAssociation'
                  - 'ec2:RequestSpotInstances'
                  - 'ec2:RevokeSecurityGroupEgress'
                  - 'ec2:RevokeSecurityGroupIngress'
                  - 'ec2:RunInstances'
                  - 'ec2:TerminateInstances'
                Resource:
                  - '*'
              - Effect: Allow
                Action:
                  - 'iam:CreateServiceLinkedRole'
                  - 'iam:PutRolePolicy'
                Resource: >-
                  arn:aws:iam::*:role/aws-service-role/spot.amazonaws.com/AWSServiceRoleForEC2Spot
                Condition:
                  StringLike:
                    'iam:AWSServiceName': spot.amazonaws.com
            Version: 2012-10-17
          PolicyName: databricks-cross-account-iam-role-policy
      Tags:
        -
          Key: Name
          Value: !Join
                  - '_'
                  - - !Ref TagValue
                    - !Sub '${AWS::StackName}-IAMRole'
  
  # Cross account access role for customer-managed VPC
  accessRoleCustomerManagedVPC:
    Type: 'AWS::IAM::Role'
    Condition: CustomerManagedVPC
    Properties:
      RoleName: !Ref IAMRole
      AssumeRolePolicyDocument:
        Statement:
          - Action: 'sts:AssumeRole'
            Condition:
               StringEquals: 
                'sts:ExternalId': !Sub '${MWSAccountId}'
            Effect: Allow
            Principal:
              AWS: !Join 
                - ''
                - - 'arn:aws:iam::'
                  - '414351767826'
                  - ':root'
            Sid: ''
        Version: 2012-10-17
      Path: /
      Policies:
        - PolicyDocument:
            Statement:
              - Sid: NonResourceBasedPermissions
                Effect: Allow
                Action:
                  - 'ec2:CancelSpotInstanceRequests'
                  - 'ec2:DescribeAvailabilityZones'
                  - 'ec2:DescribeIamInstanceProfileAssociations'
                  - 'ec2:DescribeInstanceStatus'
                  - 'ec2:DescribeInstances'
                  - 'ec2:DescribeInternetGateways'
                  - 'ec2:DescribeNatGateways'
                  - 'ec2:DescribeNetworkAcls'
                  - 'ec2:DescribePlacementGroups'
                  - 'ec2:DescribePrefixLists'
                  - 'ec2:DescribeReservedInstancesOfferings'
                  - 'ec2:DescribeRouteTables'
                  - 'ec2:DescribeSecurityGroups'
                  - 'ec2:DescribeSpotInstanceRequests'
                  - 'ec2:DescribeSpotPriceHistory'
                  - 'ec2:DescribeSubnets'
                  - 'ec2:DescribeVolumes'
                  - 'ec2:DescribeVpcAttribute'
                  - 'ec2:DescribeVpcs'
                  - 'ec2:CreatePlacementGroup'
                  - 'ec2:DeletePlacementGroup'
                  - 'ec2:CreateKeyPair'
                  - 'ec2:DeleteKeyPair'
                  - 'ec2:CreateTags'
                  - 'ec2:DeleteTags'
                  - 'ec2:RequestSpotInstances'
                Resource:
                  - '*'
              - Sid: InstancePoolsSupport
                Effect: Allow
                Action:
                  - 'ec2:AssociateIamInstanceProfile'
                  - 'ec2:DisassociateIamInstanceProfile'
                  - 'ec2:ReplaceIamInstanceProfileAssociation'
                Resource:
                  - !Sub arn:aws:ec2:${AWSRegion}:${AWSAccountId}:instance/* 
                Condition:
                  StringEquals:
                    'ec2:ResourceTag/Vendor': 'Databricks'
              - Sid: AllowEc2RunInstancePerTag
                Effect: Allow
                Action:
                  - 'ec2:RunInstances'
                Resource:
                  - !Sub arn:aws:ec2:${AWSRegion}:${AWSAccountId}:volume/*
                  - !Sub arn:aws:ec2:${AWSRegion}:${AWSAccountId}:instance/*
                Condition:
                  StringEquals:
                    'aws:RequestTag/Vendor': 'Databricks' 
              - Sid: AllowEc2RunInstanceImagePerTag
                Effect: Allow
                Action:
                  - 'ec2:RunInstances'
                Resource:
                  - !Sub arn:aws:ec2:${AWSRegion}:${AWSAccountId}:image/*
                Condition:
                  StringEquals:
                    'aws:ResourceTag/Vendor': 'Databricks'
              - Sid: AllowEc2RunInstancePerVPCid
                Effect: Allow
                Action:
                  - 'ec2:RunInstances'
                Resource:
                  - !Sub arn:aws:ec2:${AWSRegion}:${AWSAccountId}:network-interface/*
                  - !Sub arn:aws:ec2:${AWSRegion}:${AWSAccountId}:subnet/*
                  - !Sub arn:aws:ec2:${AWSRegion}:${AWSAccountId}:security-group/*
                Condition:
                  StringEquals:
                    'ec2:vpc' : !Sub 'arn:aws:ec2:${AWSRegion}:${AWSAccountId}:vpc/${VPCID}'
              - Sid: AllowEc2RunInstanceOtherResources
                Effect: Allow
                Action:
                  - 'ec2:RunInstances'
                NotResource:
                  - !Sub arn:aws:ec2:${AWSRegion}:${AWSAccountId}:image/* 
                  - !Sub arn:aws:ec2:${AWSRegion}:${AWSAccountId}:network-interface/*
                  - !Sub arn:aws:ec2:${AWSRegion}:${AWSAccountId}:subnet/*
                  - !Sub arn:aws:ec2:${AWSRegion}:${AWSAccountId}:security-group/*
                  - !Sub arn:aws:ec2:${AWSRegion}:${AWSAccountId}:volume/*
                  - !Sub arn:aws:ec2:${AWSRegion}:${AWSAccountId}:instance/*     
              - Sid: EC2TerminateInstancesTag
                Effect: Allow
                Action:
                  - 'ec2:TerminateInstances'
                Resource:
                  - !Sub arn:aws:ec2:${AWSRegion}:${AWSAccountId}:instance/*
                Condition:
                  StringEquals:
                    'ec2:ResourceTag/Vendor': 'Databricks'         
              - Sid: EC2AttachDetachVolumeTag
                Effect: Allow
                Action:
                  - 'ec2:AttachVolume'
                  - 'ec2:DetachVolume'
                Resource:
                  - !Sub arn:aws:ec2:${AWSRegion}:${AWSAccountId}:instance/* 
                  - !Sub arn:aws:ec2:${AWSRegion}:${AWSAccountId}:volume/*
                Condition:
                  StringEquals:
                    'ec2:ResourceTag/Vendor': 'Databricks'  
              - Sid: EC2CreateVolumeByTag
                Effect: Allow
                Action:
                  - 'ec2:CreateVolume'
                Resource:
                  - !Sub arn:aws:ec2:${AWSRegion}:${AWSAccountId}:volume/* 
                Condition:
                  StringEquals:
                    'aws:RequestTag/Vendor': 'Databricks'   
              - Sid: EC2DeleteVolumeByTag
                Effect: Allow
                Action:
                  - 'ec2:DeleteVolume'
                Resource:
                  - !Sub arn:aws:ec2:${AWSRegion}:${AWSAccountId}:volume/* 
                Condition:
                  StringEquals:
                    'ec2:ResourceTag/Vendor': 'Databricks'  
              - Effect: Allow
                Action:
                  - 'iam:CreateServiceLinkedRole'
                  - 'iam:PutRolePolicy'
                Resource: 
                  - arn:aws:iam::*:role/aws-service-role/spot.amazonaws.com/AWSServiceRoleForEC2Spot
                Condition:
                  StringLike:
                    'iam:AWSServiceName': spot.amazonaws.com 
              - Sid: VpcNonresourceSpecificActions
                Effect: Allow
                Action:
                  - 'ec2:AuthorizeSecurityGroupEgress'
                  - 'ec2:AuthorizeSecurityGroupIngress'
                  - 'ec2:RevokeSecurityGroupEgress'
                  - 'ec2:RevokeSecurityGroupIngress'
                Resource:
                  - !Sub arn:aws:ec2:${AWSRegion}:${AWSAccountId}:security-group/${SecurityGroupIDs}
                Condition:
                  StringEquals:
                    'ec2:vpc' : !Sub 'arn:aws:ec2:${AWSRegion}:${AWSAccountId}:vpc/${VPCID}'                                              
            Version: 2012-10-17
          PolicyName: databricks-cross-account-iam-role-policy
      Tags:
        -
          Key: Name
          Value: !Join
                  - '_'
                  - - !Ref TagValue
                    - !Sub '${AWS::StackName}-IAMRole'

  # S3 root bucket requirements
  assetsS3Bucket:
    Type: AWS::S3::Bucket
    Properties:
      BucketName: !Ref BucketName
  bucketPolicy:
    Type: 'AWS::S3::BucketPolicy'
    Properties:
      PolicyDocument:
        Id: MyPolicy
        Version: 2012-10-17
        Statement:
          - Sid: Grant Databricks Access
            Effect: Allow
            Principal:
              AWS: arn:aws:iam::414351767826:root
            Action:
              - 's3:GetObject'
              - 's3:GetObjectVersion'
              - 's3:PutObject'
              - 's3:DeleteObject'
              - 's3:ListBucket'
              - 's3:GetBucketLocation'
            Resource:
              - !Sub 'arn:aws:s3:::${assetsS3Bucket}/*'
              - !Sub 'arn:aws:s3:::${assetsS3Bucket}'
      Bucket: !Ref assetsS3Bucket                  

  # Databricks API for configuring notebook encryption with a customer-managed KMS, if provided
  createCustomerManagedKey:
    Condition: IsKMSKeyProvided
    Type: Custom::CreateCustomerManagedKey
    Properties:
      ServiceToken: !GetAtt 'databricksApiFunction.Arn'
      action: 'CREATE_CUSTOMER_MANAGED_KEY'
      accountId: !Ref MWSAccountId
      key_arn: !Ref KeyArn
      key_alias: !Ref KeyAlias
      key_region: !Ref KeyRegion
      encodedbase64: 
        Fn::Base64: !Join
          - ':'
          - - !Ref 'Username'
            - !Ref 'Password'

  # Databricks API for workspace credentials
  createCredentials:
    Type: Custom::CreateCredentials
    Properties:
      ServiceToken: !GetAtt 'databricksApiFunction.Arn'
      action: 'CREATE_CREDENTIALS'
      accountId: !Ref MWSAccountId
      credentials_name: !Join
        - '-'
        - - !Ref DeploymentName
          - 'credentials'
      role_arn: !If [CustomerManagedVPC, !GetAtt 'accessRoleCustomerManagedVPC.Arn', !GetAtt 'accessRoleDBManagedVPC.Arn']
      encodedbase64: 
        Fn::Base64: !Join
          - ':'
          - - !Ref 'Username'
            - !Ref 'Password'

  # Databricks API for workspace storage configuration    
  createStorageConfiguration:
    Type: Custom::CreateStorageConfigurations
    Properties:
      ServiceToken: !GetAtt 'databricksApiFunction.Arn'
      action: 'CREATE_STORAGE_CONFIGURATIONS'
      accountId: !Ref MWSAccountId
      storage_config_name: !Join
        - '-'
        - - !Ref 'DeploymentName'
          - 'storage'
      s3bucket_name: !Ref assetsS3Bucket
      encodedbase64: 
        Fn::Base64: !Join
          - ':'
          - - !Ref 'Username'
            - !Ref 'Password'

  # Databricks API for customer managed VPC    
  createNetworks:
    DependsOn: createStorageConfiguration
    Condition: CustomerManagedVPC
    Type: Custom::createNetworks
    Properties:
      ServiceToken: !GetAtt 'databricksApiFunction.Arn'
      action: 'CREATE_NETWORKS'
      accountId: !Ref MWSAccountId
      network_name: !Join
        - '-'
        - - !Ref 'DeploymentName'
          - 'network'
      vpc_id: !Ref VPCID
      subnet_ids: !Ref SubnetIDs
      security_group_ids: !Ref SecurityGroupIDs
      encodedbase64: 
        Fn::Base64: !Join
          - ':'
          - - !Ref 'Username'
            - !Ref 'Password'

  # Databricks API for workspace creation    
  createWorkspace:
    Type: Custom::CreateWorkspace
    Properties:
      ServiceToken: !GetAtt 'databricksApiFunction.Arn'
      action: 'CREATE_WORKSPACES'
      accountId: !Ref MWSAccountId
      workspace_name: !Join
        - '-'
        - - !Ref 'DeploymentName'
          - 'workspace'
      deployment_name: !Ref 'DeploymentName'
      aws_region: !Ref AWSRegion
      credentials_id: !GetAtt createCredentials.CredentialsId
      storage_config_id: !GetAtt createStorageConfiguration.StorageConfigId
      encodedbase64: 
        Fn::Base64: !Join
          - ':'
          - - !Ref 'Username'
            - !Ref 'Password'
      network_id: !If [CustomerManagedVPC, !GetAtt 'createNetworks.NetworkId', '']
      no_public_ip: !Ref NoPublicIP   
  
  databricksApiFunction:
    DependsOn: CopyZips
    Type: AWS::Lambda::Function
    Properties:
      Description: Get workspace status
      Handler: rest_client.handler
      Runtime: python3.8
      Role: !GetAtt 'functionRole.Arn'
      Timeout: 120
      Code:
        S3Bucket: !Ref 'LambdaZipsBucket'
        S3Key: !Sub '${QSS3KeyPrefix}functions/packages/lambda.zip'   

  # IAM Role for lambda function execution
  functionRole:
    Type: AWS::IAM::Role
    Properties:
      AssumeRolePolicyDocument:
        Version: '2012-10-17'
        Statement:
          - Effect: Allow
            Principal:
              Service: lambda.amazonaws.com
            Action: sts:AssumeRole
      ManagedPolicyArns:
        - arn:aws:iam::aws:policy/service-role/AWSLambdaBasicExecutionRole       

  # Resources to stage lambda.zip file
  LambdaZipsBucket:
    Type: AWS::S3::Bucket
  CopyZips:
    Type: Custom::CopyZips
    Properties:
      ServiceToken: !GetAtt 'CopyZipsFunction.Arn'
      DestBucket: !Ref 'LambdaZipsBucket'
      SourceBucket: !Ref 'QSS3BucketName'
      Prefix: !Ref 'QSS3KeyPrefix'
      Objects:
        - functions/packages/lambda.zip
  CopyZipsRole:
    Type: AWS::IAM::Role
    Properties:
      AssumeRolePolicyDocument:
        Version: '2012-10-17'
        Statement:
          - Effect: Allow
            Principal:
              Service: lambda.amazonaws.com
            Action: sts:AssumeRole
      ManagedPolicyArns:
        - arn:aws:iam::aws:policy/service-role/AWSLambdaBasicExecutionRole
      Path: /
      Policies:
        - PolicyName: lambda-copier
          PolicyDocument:
            Version: '2012-10-17'
            Statement:
              - Effect: Allow
                Action:
                  - s3:GetObject
                Resource:
                  - !Sub 'arn:aws:s3:::${QSS3BucketName}/${QSS3KeyPrefix}*'
              - Effect: Allow
                Action:
                  - s3:PutObject
                  - s3:DeleteObject
                Resource:
                  - !Sub 'arn:aws:s3:::${LambdaZipsBucket}/${QSS3KeyPrefix}*'

  CopyZipsFunction:
    Type: AWS::Lambda::Function
    Properties:
      Description: Copies objects from a source S3 bucket to a destination
      Handler: index.handler
      Runtime: python2.7
      Role: !GetAtt 'CopyZipsRole.Arn'
      Timeout: 240
      Code:
        ZipFile: |
          import json
          import logging
          import threading
          import boto3
          import cfnresponse
          def copy_objects(source_bucket, dest_bucket, prefix, objects):
              s3 = boto3.client('s3')
              for o in objects:
                  key = prefix + o
                  copy_source = {
                      'Bucket': source_bucket,
                      'Key': key
                  }
                  print('copy_source: %s' % copy_source)
                  print('dest_bucket = %s'%dest_bucket)
                  print('key = %s' %key)
                  s3.copy_object(CopySource=copy_source, Bucket=dest_bucket,
                        Key=key)
          def delete_objects(bucket, prefix, objects):
              s3 = boto3.client('s3')
              objects = {'Objects': [{'Key': prefix + o} for o in objects]}
              s3.delete_objects(Bucket=bucket, Delete=objects)
          def timeout(event, context):
              logging.error('Execution is about to time out, sending failure response to CloudFormation')
              cfnresponse.send(event, context, cfnresponse.FAILED, {}, None)
          def handler(event, context):
              # make sure we send a failure to CloudFormation if the function
              # is going to timeout
              timer = threading.Timer((context.get_remaining_time_in_millis()
                        / 1000.00) - 0.5, timeout, args=[event, context])
              timer.start()
              print('Received event: %s' % json.dumps(event))
              status = cfnresponse.SUCCESS
              try:
                  source_bucket = event['ResourceProperties']['SourceBucket']
                  dest_bucket = event['ResourceProperties']['DestBucket']
                  prefix = event['ResourceProperties']['Prefix']
                  objects = event['ResourceProperties']['Objects']
                  if event['RequestType'] == 'Delete':
                      delete_objects(dest_bucket, prefix, objects)
                  else:
                      copy_objects(source_bucket, dest_bucket, prefix, objects)
              except Exception as e:
                  logging.error('Exception: %s' % e, exc_info=True)
                  status = cfnresponse.FAILED
              finally:
                  timer.cancel()
                  cfnresponse.send(event, context, status, {}, None)
                  
